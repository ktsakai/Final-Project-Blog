[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "myblog",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nFinal Project Related Assignment\n\n\n\n\n\nDraft of Final Project\n\n\n\n\n\n\nJul 30, 2023\n\n\nKaelyn Sakai\n\n\n\n\n\n\n  \n\n\n\n\nSpotify Top Songs Analysis\n\n\n\n\n\nDigital Humanities 140 Final Project\n\n\n\n\n\n\nJul 30, 2023\n\n\nKaelyn Sakai\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJul 28, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\nFirst File\n\n\n\n\n\nTesting Quarto\n\n\n\n\n\n\nJul 26, 2023\n\n\nKaelyn Sakai\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/Final Project Notebook Draft.html",
    "href": "posts/Final Project Notebook Draft.html",
    "title": "Final Project Related Assignment",
    "section": "",
    "text": "Kaelyn Sakai • July 2023"
  },
  {
    "objectID": "posts/Final Project Notebook Draft.html#project-introduction",
    "href": "posts/Final Project Notebook Draft.html#project-introduction",
    "title": "Final Project Related Assignment",
    "section": "Project Introduction",
    "text": "Project Introduction\nThe dataset I that I plan on investigating further is the Spotify Top Songs Data from Kaggle. The data contains information about a variety of Billboard top songs. I wanted to analyze this, because I have always been interested in music trends and music in general. Music throughout history is consistently changing, and exploring this dataset can help to further understand the types of songs that have been popular recently. The main research question I will be addressing is, “What types of songs were the most popular in the 2010’s and can correlations be drawn between the different variables that contribute to the song popularity?”."
  },
  {
    "objectID": "posts/Final Project Notebook Draft.html#data-exploration-and-introduction",
    "href": "posts/Final Project Notebook Draft.html#data-exploration-and-introduction",
    "title": "Final Project Related Assignment",
    "section": "Data Exploration and Introduction",
    "text": "Data Exploration and Introduction\nThis data contains some of the top songs between the years 2010 through 2019. This is a brief overview of the data and what each variable represents.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntop genre\nGenre of the track\n\n\nyear\nThe year the song appeared on Billboard\n\n\nbpm\nBeats per minute of the song\n\n\nnrgy\nEnergy: The energy rating of the song - the higher the nrgy score, the more energetic the song is\n\n\ndnce\nDance: The danceability rating of the song - the higher the dnce score, the easier it is to dance to\n\n\ndB\nDecibels: The overall loudness - the higher the dB, the louder the song\n\n\nlive\nThe higher the value, the more likely the song is a live recording\n\n\nval\nValence: The mood of the song - the higher the valence, the more cheerful the song is\n\n\ndur\nDuration: Length of the song in seconds\n\n\nacous\nAcoustics: The higher the acoustic value, the more acoustic the song is\n\n\nspch\nSpeechiness: The higher the value, the song contains more spoken words\n\n\npop\nPopularity: Measures how popular the song was\n\n\n\n\nimport matplotlib.pyplot as plt\n\n\nimport pandas as pd\ndf = pd.read_csv('spotify.csv',encoding='latin-1')\n\nFileNotFoundError: [Errno 2] No such file or directory: 'spotify.csv'\n\n\nThe table above shows an overview of the dataset I will be using. There are 603 songs included, with 14 columns describing them.\n\ndf.describe()\n\n\n\n\n\n\n\n\nUnnamed: 0\nyear\nbpm\nnrgy\ndnce\ndB\nlive\nval\ndur\nacous\nspch\npop\n\n\n\n\ncount\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n\n\nmean\n302.000000\n2014.592040\n118.545605\n70.504146\n64.379768\n-5.578773\n17.774461\n52.225539\n224.674959\n14.326700\n8.358209\n66.520730\n\n\nstd\n174.215384\n2.607057\n24.795358\n16.310664\n13.378718\n2.798020\n13.102543\n22.513020\n34.130059\n20.766165\n7.483162\n14.517746\n\n\nmin\n1.000000\n2010.000000\n0.000000\n0.000000\n0.000000\n-60.000000\n0.000000\n0.000000\n134.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n151.500000\n2013.000000\n100.000000\n61.000000\n57.000000\n-6.000000\n9.000000\n35.000000\n202.000000\n2.000000\n4.000000\n60.000000\n\n\n50%\n302.000000\n2015.000000\n120.000000\n74.000000\n66.000000\n-5.000000\n12.000000\n52.000000\n221.000000\n6.000000\n5.000000\n69.000000\n\n\n75%\n452.500000\n2017.000000\n129.000000\n82.000000\n73.000000\n-4.000000\n24.000000\n69.000000\n239.500000\n17.000000\n9.000000\n76.000000\n\n\nmax\n603.000000\n2019.000000\n206.000000\n98.000000\n97.000000\n-2.000000\n74.000000\n98.000000\n424.000000\n99.000000\n48.000000\n99.000000\n\n\n\n\n\n\n\n\ndf.plot(kind='scatter',x='year',y='val',color='lightblue')\n\n&lt;Axes: xlabel='year', ylabel='val'&gt;\n\n\n\n\n\n\nc = df['artist'].value_counts().nlargest(15)\nc.plot(kind='bar',color='pink')\n\n&lt;Axes: &gt;\n\n\n\n\n\n\ndf.plot(kind='scatter',x='nrgy',y='pop',color='purple')\n\n&lt;Axes: xlabel='nrgy', ylabel='pop'&gt;\n\n\n\n\n\n\ng = df['top genre'].value_counts().nlargest(15)\ng.plot(kind='bar',color='mediumturquoise')\n\n&lt;Axes: &gt;"
  },
  {
    "objectID": "posts/Final Project Notebook Draft.html#data-analysis",
    "href": "posts/Final Project Notebook Draft.html#data-analysis",
    "title": "Final Project Related Assignment",
    "section": "Data Analysis",
    "text": "Data Analysis\n\nimport requests\nimport matplotlib.pyplot as plt\nimport nltk\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.sentiment import vader\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import opinion_lexicon\nfrom nltk.stem.porter import PorterStemmer\n\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('vader_lexicon')\nnltk.download('opinion_lexicon')\n\n[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n[nltk_data] Downloading package opinion_lexicon to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Package opinion_lexicon is already up-to-date!\n\n\nTrue\n\n\n\nsia = vader.SentimentIntensityAnalyzer()\n\n\ncol_list = df[\"title\"].values.tolist()\ntitle = ' '.join(col_list)\ntitle_lower = title.lower()\n\n\nfrom nltk.tokenize import word_tokenize, sent_tokenize\ndef tokenize(string):\n  sent = sent_tokenize(title_lower)\n  words = []\n  for s in sent:\n      for w in word_tokenize(s):\n          words.append(w)\n  return words\n\nwords = tokenize(title_lower)\nprint(words)\n\n['hey', ',', 'soul', 'sister', 'love', 'the', 'way', 'you', 'lie', 'tik', 'tok', 'bad', 'romance', 'just', 'the', 'way', 'you', 'are', 'baby', 'dynamite', 'secrets', 'empire', 'state', 'of', 'mind', '(', 'part', 'ii', ')', 'broken', 'down', 'only', 'girl', '(', 'in', 'the', 'world', ')', 'club', 'ca', \"n't\", 'handle', 'me', '(', 'feat', '.', 'david', 'guetta', ')', 'marry', 'you', 'cooler', 'than', 'me', '-', 'single', 'mix', 'telephone', 'like', 'a', 'g6', 'omg', '(', 'feat', '.', 'will.i.am', ')', 'eenie', 'meenie', 'the', 'time', '(', 'dirty', 'bit', ')', 'alejandro', 'your', 'love', 'is', 'my', 'drug', 'meet', 'me', 'halfway', 'whataya', 'want', 'from', 'me', 'take', 'it', 'off', 'misery', 'all', 'the', 'right', 'moves', 'animal', 'naturally', 'i', 'like', 'it', 'teenage', 'dream', 'california', 'gurls', '3', 'my', 'first', 'kiss', '-', 'feat', '.', 'ke', '$', 'ha', 'blah', 'blah', 'blah', '(', 'feat', '.', '3oh', '!', '3', ')', 'imma', 'be', 'try', 'sleeping', 'with', 'a', 'broken', 'heart', 'sexy', 'bitch', '(', 'feat', '.', 'akon', ')', 'bound', 'to', 'you', '-', 'burlesque', 'original', 'motion', 'picture', 'soundtrack', 'if', 'i', 'had', 'you', 'rock', 'that', 'body', 'dog', 'days', 'are', 'over', 'something', \"'s\", 'got', 'a', 'hold', 'on', 'me', '-', 'burlesque', 'original', 'motion', 'picture', 'soundtrack', 'does', \"n't\", 'mean', 'anything', 'hard', 'loca', 'you', 'lost', 'me', 'not', 'myself', 'tonight', 'written', 'in', 'the', 'stars', '(', 'feat', '.', 'eric', 'turner', ')', 'dj', 'got', 'us', 'fallin', \"'\", 'in', 'love', '(', 'feat', '.', 'pitbull', ')', 'castle', 'walls', '(', 'feat', '.', 'christina', 'aguilera', ')', 'break', 'your', 'heart', 'hello', 'a', 'thousand', 'years', 'someone', 'like', 'you', 'give', 'me', 'everything', 'just', 'the', 'way', 'you', 'are', 'rolling', 'in', 'the', 'deep', 'run', 'the', 'world', '(', 'girls', ')', 'moves', 'like', 'jagger', '-', 'studio', 'recording', 'from', 'the', 'voice', 'performance', 'love', 'on', 'top', 'grenade', 'tonight', 'tonight', 'what', 'the', 'hell', 'born', 'this', 'way', 'monster', 'marry', 'you', 'best', 'thing', 'i', 'never', 'had', 'party', 'rock', 'anthem', 'we', 'r', 'who', 'we', 'r', 'price', 'tag', 'good', 'life', 'just', 'can\\x92t', 'get', 'enough', 'on', 'the', 'floor', 'what', \"'s\", 'my', 'name', '?', 'yeah', '3x', 'without', 'you', '(', 'feat', '.', 'usher', ')', 'sexy', 'and', 'i', 'know', 'it', 'the', 'edge', 'of', 'glory', 'e.t', '.', 'till', 'the', 'world', 'ends', 'i', 'wan', 'na', 'go', 'blow', 'you', 'and', 'i', 'judas', 'tonight', '(', 'i', \"'m\", 'fuckin', \"'\", 'you', ')', 'please', 'do', \"n't\", 'go', 'we', 'found', 'love', 'marry', 'the', 'night', '1+1', 'hold', 'it', 'against', 'me', 'i', \"'m\", 'into', 'you', 'papi', 'cheers', '(', 'drink', 'to', 'that', ')', 's', '&', 'm', 'remix', 'written', 'in', 'the', 'stars', '(', 'feat', '.', 'eric', 'turner', ')', 'jar', 'of', 'hearts', 'castle', 'walls', '(', 'feat', '.', 'christina', 'aguilera', ')', 'turning', 'page', 'super', 'bass', 'raise', 'your', 'glass', 'invading', 'my', 'mind', 'moment', '4', 'life', '-', 'album', 'version', '(', 'edited', ')', 'last', 'friday', 'night', '(', 't.g.i.f', '.', ')', 'firework', 'muny', '-', 'album', 'version', '(', 'edited', ')', 'titanium', '(', 'feat', '.', 'sia', ')', 'locked', 'out', 'of', 'heaven', 'paradise', 'payphone', 'what', 'makes', 'you', 'beautiful', 'i', 'knew', 'you', 'were', 'trouble', '.', 'call', 'me', 'maybe', 'love', 'you', 'like', 'a', 'love', 'song', 'set', 'fire', 'to', 'the', 'rain', 'we', 'are', 'never', 'ever', 'getting', 'back', 'together', 'stronger', '(', 'what', 'does', \"n't\", 'kill', 'you', ')', 'try', 'starships', 'one', 'more', 'night', 'good', 'time', 'glad', 'you', 'came', 'beauty', 'and', 'a', 'beat', 'international', 'love', 'some', 'nights', 'boyfriend', 'part', 'of', 'me', 'domino', 'where', 'have', 'you', 'been', 'wide', 'awake', 'the', 'one', 'that', 'got', 'away', 'dance', 'again', 'turn', 'up', 'the', 'music', 'lights', '-', 'single', 'version', 'we', 'are', 'young', '(', 'feat', '.', 'janelle', 'monáe', ')', 'diamonds', 'do', \"n't\", 'stop', 'the', 'party', '(', 'feat', '.', 'tjr', ')', 'you', 'da', 'one', 'stereo', 'hearts', '(', 'feat', '.', 'adam', 'levine', ')', 'it', 'will', 'rain', 'blow', 'me', '(', 'one', 'last', 'kiss', ')', 'underneath', 'the', 'tree', 'wake', 'me', 'up', 'story', 'of', 'my', 'life', 'just', 'give', 'me', 'a', 'reason', '(', 'feat', '.', 'nate', 'ruess', ')', 'hall', 'of', 'fame', 'roar', 'we', 'ca', \"n't\", 'stop', 'do', \"n't\", 'you', 'worry', 'child', '-', 'radio', 'edit', 'get', 'lucky', '(', 'feat', '.', 'pharrell', 'williams', '&', 'nile', 'rodgers', ')', '-', 'radio', 'edit', 'wrecking', 'ball', 'impossible', 'blurred', 'lines', 'heart', 'attack', 'we', 'are', 'never', 'ever', 'getting', 'back', 'together', 'die', 'young', 'clarity', 'summertime', 'sadness', '(', 'lana', 'del', 'rey', 'vs.', 'cedric', 'gervais', ')', '-', 'cedric', 'gervais', 'remix', 'under', 'control', 'everybody', 'talks', 'hold', 'on', ',', 'we', \"'re\", 'going', 'home', 'best', 'song', 'ever', 'kiss', 'you', 'sweet', 'nothing', '(', 'feat', '.', 'florence', 'welch', ')', 'lose', 'yourself', 'to', 'dance', 'work', 'bitch', 'brave', 'ca', \"n't\", 'hold', 'us', '(', 'feat', '.', 'ray', 'dalton', ')', 'feel', 'this', 'moment', '(', 'feat', '.', 'christina', 'aguilera', ')', 'beneath', 'your', 'beautiful', 'let', 'me', 'love', 'you', '(', 'until', 'you', 'learn', 'to', 'love', 'yourself', ')', 'thrift', 'shop', '(', 'feat', '.', 'wanz', ')', 'if', 'i', 'lose', 'myself', '-', 'alesso', 'vs', 'onerepublic', 'the', 'way', 'suit', '&', 'tie', '#', 'thatpower', 'i', 'love', 'it', '(', 'feat', '.', 'charli', 'xcx', ')', 'play', 'hard', '(', 'feat', '.', 'ne-yo', '&', 'akon', ')', '-', 'new', 'edit', 'daylight', 'love', 'somebody', 'a', 'little', 'party', 'never', 'killed', 'nobody', '(', 'all', 'we', 'got', ')', 'move', 'walks', 'like', 'rihanna', 'rock', 'n', 'roll', 'heartbreaker', 'mirrors', '-', 'radio', 'edit', 'next', 'to', 'me', 'made', 'in', 'the', 'usa', 'clown', 'girl', 'on', 'fire', '(', 'feat', '.', 'nicki', 'minaj', ')', '-', 'inferno', 'version', 'tko', 'come', '&', 'get', 'it', 'live', 'it', 'up', 'we', 'own', 'the', 'night', 'atlas', '-', 'from', '\\x93the', 'hunger', 'games', ':', 'catching', 'fire\\x94', 'soundtrack', 'what', 'about', 'love', 'take', 'back', 'the', 'night', 'applause', 'anything', 'could', 'happen', 'finally', 'found', 'you', 'pom', 'poms', '#', 'beautiful', 'how', 'ya', 'doin', \"'\", '?', '(', 'feat', '.', 'missy', 'elliott', ')', 'crazy', 'kids', '(', 'feat', '.', 'will.i.am', ')', 'ooh', 'la', 'la', '(', 'from', '``', 'the', 'smurfs', '2', \"''\", ')', 'people', 'like', 'us', 'overdose', 'right', 'now', '-', 'dyro', 'radio', 'edit', 'give', 'it', '2', 'u', 'foolish', 'games', 'outta', 'nowhere', '(', 'feat', '.', 'danny', 'mercer', ')', 'freak', 'all', 'of', 'me', 'stay', 'with', 'me', 'summer', 'happy', '-', 'from', '``', 'despicable', 'me', '2', \"''\", 'rude', 'shake', 'it', 'off', 'dark', 'horse', 'hey', 'brother', 'maps', 'treasure', 'let', 'her', 'go', 'problem', 'pompeii', 'team', 'love', 'me', 'again', 'latch', 'adore', 'you', 'love', 'never', 'felt', 'so', 'good', 'burn', 'she', 'looks', 'so', 'perfect', 'fancy', 'talk', 'dirty', '(', 'feat', '.', '2', 'chainz', ')', 'gorilla', 'human', 'young', 'girls', 'wiggle', '(', 'feat', '.', 'snoop', 'dogg', ')', 'love', 'runs', 'out', 'this', 'is', 'how', 'we', 'do', 'mmm', 'yeah', '(', 'feat', '.', 'pitbull', ')', 'a', 'little', 'party', 'never', 'killed', 'nobody', '(', 'all', 'we', 'got', ')', '#', 'selfie', 'partition', 'birthday', 'g.u.y', '.', 'stay', 'the', 'night', '-', 'featuring', 'hayley', 'williams', 'of', 'paramore', 'let', 'it', 'go', '-', 'from', '``', 'frozen', '/', 'single', 'version', 'wings', 'ca', \"n't\", 'remember', 'to', 'forget', 'you', '(', 'feat', '.', 'rihanna', ')', 'shot', 'me', 'down', '(', 'feat', '.', 'skylar', 'grey', ')', '-', 'radio', 'edit', 'say', 'something', 'a', 'sky', 'full', 'of', 'stars', 'come', 'get', 'it', 'bae', 'chandelier', 'xo', 'we', 'are', 'one', '(', 'ole', 'ola', ')', '[', 'the', 'official', '2014', 'fifa', 'world', 'cup', 'song', ']', 'not', 'about', 'angels', 'drunk', 'in', 'love', 'anaconda', 'boom', 'clap', '-', 'from', 'the', 'motion', 'picture', 'das', 'schicksal', 'ist', 'ein', 'mieser', 'verräter', 'la', 'la', 'la', '(', 'brasil', '2014', ')', '(', 'feat', '.', 'carlinhos', 'brown', ')', 'tee', 'shirt', '-', 'soundtrack', 'version', 'words', 'as', 'weapons', 'you', \"'re\", 'mine', '(', 'eternal', ')', 'sheezus', 'cannonball', 'it', \"'s\", 'on', 'again', '-', 'main', 'soundtrack', 'i', 'luh', 'ya', 'papi', 'not', 'a', 'bad', 'thing', 'thinking', 'out', 'loud', 'i', \"'m\", 'not', 'the', 'only', 'one', 'the', 'hills', 'love', 'yourself', 'uptown', 'funk', 'take', 'me', 'to', 'church', 'sugar', 'sorry', 'fourfiveseconds', 'love', 'me', 'like', 'you', 'do', '-', 'from', '``', 'fifty', 'shades', 'of', 'grey', \"''\", 'earned', 'it', '(', 'fifty', 'shades', 'of', 'grey', ')', '-', 'from', 'the', '``', 'fifty', 'shades', 'of', 'grey', \"''\", 'soundtrack', 'what', 'do', 'you', 'mean', '?', 'stitches', 'want', 'to', 'want', 'me', 'my', 'house', 'waves', '-', 'robin', 'schulz', 'radio', 'edit', 'night', 'changes', 'how', 'deep', 'is', 'your', 'love', 'never', 'forget', 'you', 'love', 'me', 'harder', 'animals', 'blame', 'worth', 'it', 'break', 'free', 'do', \"n't\", 'elastic', 'heart', 'rather', 'be', '(', 'feat', '.', 'jess', 'glynne', ')', 'hello', 'dear', 'future', 'husband', '43776', 'the', 'heart', 'wants', 'what', 'it', 'wants', 'hey', 'mama', '(', 'feat', '.', 'nicki', 'minaj', ',', 'bebe', 'rexha', '&', 'afrojack', ')', 'genie', 'in', 'a', 'bottle', 'company', 'sing', 'jealous', '-', 'remix', 'really', 'do', \"n't\", 'care', 'downtown', '(', 'feat', '.', 'melle', 'mel', ',', 'grandmaster', 'caz', ',', 'kool', 'moe', 'dee', '&', 'eric', 'nally', ')', 'only', 'love', 'can', 'hurt', 'like', 'this', 'heartbeat', 'song', 'up', 'trumpets', 'runnin', \"'\", '(', 'lose', 'it', 'all', ')', 'same', 'old', 'love', 'i', 'want', 'you', 'to', 'know', 'lips', 'are', 'movin', 'i', \"'ll\", 'show', 'you', 'here', 'i', 'lived', 'fireball', '(', 'feat', '.', 'john', 'ryan', ')', 'easy', 'love', 'the', 'feeling', 'i', 'really', 'like', 'you', 'bo', '$', '$', 'sugar', 'focus', 'all', 'about', 'that', 'bass', 'on', 'my', 'mind', 'love', 'me', 'like', 'you', 'broken', 'arrows', 'booty', 'what', 'do', 'you', 'mean', '?', '-', 'acoustic', 'mark', 'my', 'words', 'lay', 'it', 'all', 'on', 'me', 'american', 'oxygen', 'bang', 'bang', 'reality', '-', 'radio', 'edit', 'alive', 'sugar', '(', 'feat', '.', 'francesco', 'yates', ')', 'been', 'you', 'prayer', 'in', 'c', '-', 'robin', 'schulz', 'radio', 'edit', 'see', 'you', 'again', '(', 'feat', '.', 'charlie', 'puth', ')', 'heroes', '(', 'we', 'could', 'be', ')', 'feel', 'the', 'light', '-', 'from', 'the', '``', 'home', \"''\", 'soundtrack', 'perfect', 'ghosttown', 'bang', 'my', 'head', '(', 'feat', '.', 'sia', '&', 'fetty', 'wap', ')', 'bloodstream', 'living', 'for', 'love', 'baby', 'do', \"n't\", 'lie', 'do', \"n't\", 'be', 'so', 'hard', 'on', 'yourself', 'steal', 'my', 'girl', 'celebrate', '(', 'from', 'the', 'original', 'motion', 'picture', '``', 'penguins', 'of', 'madagascar', \"''\", ')', 'we', 'are', 'here', 'st', 'jude', 'yesterday', '(', 'feat', '.', 'bebe', 'rexha', ')', 'time', 'of', 'our', 'lives', 'sparks', 'mr.', 'put', 'it', 'down', 'legendary', 'lovers', 'spark', 'the', 'fire', 'run', 'run', 'run', 'let', 'me', 'be', 'your', 'lover', 'dangerous', 'l.a.love', '(', 'la', 'la', ')', 'the', 'hills', 'love', 'yourself', 'cake', 'by', 'the', 'ocean', 'do', \"n't\", 'let', 'me', 'down', 'in', 'the', 'name', 'of', 'love', 'into', 'you', 'this', 'is', 'what', 'you', 'came', 'for', 'million', 'reasons', 'needed', 'me', '7', 'years', 'ca', \"n't\", 'stop', 'the', 'feeling', '!', '(', 'original', 'song', 'from', 'dreamworks', 'animation', \"'s\", '``', 'trolls', \"''\", ')', 'work', 'from', 'home', '(', 'feat', '.', 'ty', 'dolla', '$', 'ign', ')', 'scars', 'to', 'your', 'beautiful', 'like', 'i', \"'m\", 'gon', 'na', 'lose', 'you', '(', 'feat', '.', 'john', 'legend', ')', 'work', 'stitches', 'me', ',', 'myself', '&', 'i', 'i', 'took', 'a', 'pill', 'in', 'ibiza', '-', 'seeb', 'remix', 'dangerous', 'woman', 'starving', 'shout', 'out', 'to', 'my', 'ex', 'electric', 'love', 'confident', 'too', 'good', 'roses', 'cold', 'water', '(', 'feat', '.', 'justin', 'bieber', '&', 'mø', ')', 'me', 'too', 'light', 'it', 'up', '(', 'feat', '.', 'nyla', '&', 'fuse', 'odg', ')', '[', 'remix', ']', 'ai', \"n't\", 'your', 'mama', 'close', 'toothbrush', 'all', 'we', 'know', 'final', 'song', 'company', 'hands', 'to', 'myself', 'all', 'i', 'ask', 'just', 'like', 'fire', '(', 'from', 'the', 'original', 'motion', 'picture', '``', 'alice', 'through', 'the', 'looking', 'glass', \"''\", ')', 'no', 'kill', 'em', 'with', 'kindness', 'cool', 'girl', 'runnin', \"'\", '(', 'lose', 'it', 'all', ')', 'here', 'perfect', 'illusion', 'pillowtalk', 'out', 'of', 'the', 'woods', 'rise', 'wherever', 'i', 'go', 'body', 'say', 'do', \"n't\", 'be', 'a', 'fool', 'like', 'i', 'would', 'cheap', 'thrills', 'i', 'got', 'you', 'run', 'away', 'with', 'me', 'cruel', '(', 'feat', '.', 'zayn', ')', 'send', 'my', 'love', '(', 'to', 'your', 'new', 'lover', ')', 'wtf', '(', 'where', 'they', 'from', ')', 'desire', 'when', 'we', 'were', 'young', 'i', 'know', 'what', 'you', 'did', 'last', 'summer', 'wish', 'that', 'you', 'were', 'here', '-', 'from', '\\x93miss', 'peregrine\\x92s', 'home', 'for', 'peculiar', 'children\\x94', 'original', 'motion', 'picture', 'hurts', 'change', 'make', 'me', '...', '(', 'feat', '.', 'g-eazy', ')', 'keeping', 'your', 'head', 'up', 'true', 'colors', 'make', 'me', 'like', 'you', 'champagne', 'problems', 'blown', 'start', 'pep', 'rally', 'higher', 'invitation', 'one', 'call', 'away', '(', 'feat', '.', 'tyga', ')', '-', 'remix', 'beautiful', 'birds', '(', 'feat', '.', 'birdy', ')', 'little', 'lies', 'do', 'you', 'wan', 'na', 'come', 'over', '?', 'burnitup', '!', 'picky', '-', 'remix', 'behind', 'your', 'back', 'million', 'years', 'ago', 'shape', 'of', 'you', 'closer', 'starboy', 'treat', 'you', 'better', 'that', \"'s\", 'what', 'i', 'like', 'let', 'me', 'love', 'you', 'i', 'feel', 'it', 'coming', 'mercy', 'side', 'to', 'side', 'stay', 'it', 'ai', \"n't\", 'me', '(', 'with', 'selena', 'gomez', ')', 'malibu', 'something', 'just', 'like', 'this', 'rockabye', '(', 'feat', '.', 'sean', 'paul', '&', 'anne-marie', ')', 'i', 'don\\x92t', 'wan', 'na', 'live', 'forever', '(', 'fifty', 'shades', 'darker', ')', 'my', 'way', 'i', \"'m\", 'the', 'one', '(', 'feat', '.', 'justin', 'bieber', ',', 'quavo', ',', 'chance', 'the', 'rapper', '&', 'lil', 'wayne', ')', 'praying', 'despacito', '-', 'remix', 'the', 'greatest', 'there', 'for', 'you', 'paris', 'crying', 'in', 'the', 'club', 'mama', 'slide', '(', 'feat', '.', 'frank', 'ocean', '&', 'migos', ')', 'swish', 'swish', 'chained', 'to', 'the', 'rhythm', 'cold', '(', 'feat', '.', 'future', ')', 'love', 'reggaetón', 'lento', '(', 'remix', ')', 'all', 'i', 'ask', 'first', 'time', 'the', 'cure', 'how', 'far', 'i', \"'ll\", 'go', '-', 'from', '``', 'moana', \"''\", 'bodak', 'yellow', 'rich', 'love', '(', 'with', 'seeb', ')', 'tired', 'came', 'here', 'for', 'love', '24k', 'magic', 'strip', 'that', 'down', '(', 'feat', '.', 'quavo', ')', 'cut', 'to', 'the', 'feeling', 'ok', '-', 'spotify', 'version', 'bon', 'appétit', 'summer', 'bummer', '(', 'feat', '.', 'a', '$', 'ap', 'rocky', '&', 'playboi', 'carti', ')', 'get', 'low', '(', 'with', 'liam', 'payne', ')', 'kissing', 'strangers', 'slow', 'hands', 'younger', 'now', 'body', 'moves', 'reality', '(', 'feat', '.', 'janieck', 'devy', ')', '-', 'radio', 'edit', 'angel', 'touch', '(', 'feat', '.', 'kid', 'ink', ')', 'we', 'do', \"n't\", 'talk', 'anymore', '-', 'droeloe', 'remix', 'love', 'incredible', '(', 'feat', '.', 'camila', 'cabello', ')', 'no', 'vacancy', '(', 'with', 'sebastián', 'yatra', ')', 'rich', 'boy', 'lust', 'for', 'life', '(', 'with', 'the', 'weeknd', ')', 'greenlight', '(', 'feat', '.', 'flo', 'rida', '&', 'lunchmoney', 'lewis', ')', 'influence', 'remember', 'i', 'told', 'you', 'messin', \"'\", 'around', 'water', 'under', 'the', 'bridge', 'free', 'me', 'kissing', 'strangers', '-', 'remix', 'a', 'l', 'i', 'e', 'n', 's', 'one', 'kiss', '(', 'with', 'dua', 'lipa', ')', 'havana', '(', 'feat', '.', 'young', 'thug', ')', 'i', 'like', 'it', 'new', 'rules', 'there', \"'s\", 'nothing', 'holdin', \"'\", 'me', 'back', 'no', 'tears', 'left', 'to', 'cry', 'idgaf', 'in', 'my', 'blood', 'wolves', 'dusk', 'till', 'dawn', '-', 'radio', 'edit', 'attention', 'electricity', '(', 'with', 'dua', 'lipa', ')', 'love', 'on', 'the', 'brain', 'let', 'me', 'go', '(', 'with', 'alesso', ',', 'florida', 'georgia', 'line', '&', 'watt', ')', 'silence', 'sorry', 'not', 'sorry', 'shallow', '-', 'radio', 'edit', 'these', 'days', 'what', 'lovers', 'do', '(', 'feat', '.', 'sza', ')', 'finesse', '-', 'remix', ';', 'feat', '.', 'cardi', 'b', 'perfect', 'duet', '(', 'ed', 'sheeran', '&', 'beyoncé', ')', 'bad', 'at', 'love', 'him', '&', 'i', '(', 'with', 'halsey', ')', 'friends', '(', 'with', 'bloodpop®', ')', 'wild', 'thoughts', '(', 'feat', '.', 'rihanna', '&', 'bryson', 'tiller', ')', 'my', 'my', 'my', '!', 'capital', 'letters', 'sick', 'boy', 'tequila', 'look', 'what', 'you', 'made', 'me', 'do', 'youth', '(', 'feat', '.', 'khalid', ')', 'bad', 'liar', 'anywhere', 'say', 'something', 'chun-li', 'sign', 'of', 'the', 'times', 'familiar', 'let', 'me', 'supernova', 'nervous', 'first', 'time', 'end', 'game', 'mi', 'gente', '(', 'feat', '.', 'beyoncé', ')', 'lemon', 'for', 'you', '(', 'with', 'rita', 'ora', ')', 'want', 'to', 'what', 'i', 'need', '(', 'feat', '.', 'kehlani', ')', 'wait', 'what', 'about', 'us', 'kissing', 'strangers', '2u', '(', 'feat', '.', 'justin', 'bieber', ')', 'walk', 'on', 'water', '(', 'feat', '.', 'beyoncé', ')', 'this', 'town', 'girls', '(', 'feat', '.', 'cardi', 'b', ',', 'bebe', 'rexha', '&', 'charli', 'xcx', ')', 'move', 'to', 'miami', 'miss', 'you', '(', 'with', 'major', 'lazer', '&', 'tory', 'lanez', ')', 'filthy', 'never', 'be', 'the', 'same', '-', 'radio', 'edit', 'ferrari', 'supplies', 'boom', 'boom', '...', 'ready', 'for', 'it', '?', '-', 'bloodpop®', 'remix', 'drip', '(', 'feat', '.', 'migos', ')', 'tell', 'me', 'you', 'love', 'me', '-', 'notd', 'remix', 'memories', 'lose', 'you', 'to', 'love', 'me', 'someone', 'you', 'loved', 'señorita', 'how', 'do', 'you', 'sleep', '?', 'south', 'of', 'the', 'border', '(', 'feat', '.', 'camila', 'cabello', '&', 'cardi', 'b', ')', 'trampoline', '(', 'with', 'zayn', ')', 'happier', 'truth', 'hurts', 'good', 'as', 'hell', '(', 'feat', '.', 'ariana', 'grande', ')', '-', 'remix', 'higher', 'love', 'only', 'human', 'beautiful', 'people', '(', 'feat', '.', 'khalid', ')', 'sucker', 'do', \"n't\", 'call', 'me', 'up', 'i', 'do', \"n't\", 'care', '(', 'with', 'justin', 'bieber', ')', 'talk', '(', 'feat', '.', 'disclosure', ')', 'giant', '(', 'with', \"rag'n'bone\", 'man', ')', 'takeaway', 'all', 'around', 'the', 'world', '(', 'la', 'la', 'la', ')', 'girls', 'like', 'you', '(', 'feat', '.', 'cardi', 'b', ')', 'call', 'you', 'mine', 'no', 'guidance', '(', 'feat', '.', 'drake', ')', 'antisocial', '(', 'with', 'travis', 'scott', ')', 'taki', 'taki', '(', 'feat', '.', 'selena', 'gomez', ',', 'ozuna', '&', 'cardi', 'b', ')', 'con', 'calma', '-', 'remix', 'find', 'u', 'again', '(', 'feat', '.', 'camila', 'cabello', ')', 'cross', 'me', '(', 'feat', '.', 'chance', 'the', 'rapper', '&', 'pnb', 'rock', ')', 'no', 'brainer', '(', 'feat', '.', 'justin', 'bieber', ',', 'chance', 'the', 'rapper', '&', 'quavo', ')', 'nothing', 'breaks', 'like', 'a', 'heart', '(', 'feat', '.', 'miley', 'cyrus', ')', 'kills', 'you', 'slowly']\n\n\n\ndef score_words(words):\n  positive = []\n  negative = []\n  for i in words:\n    scores = sia.polarity_scores(i)\n    if scores[\"compound\"] &gt; 0:\n      positive.append(i)\n    elif scores[\"compound\"] &lt; 0:\n      negative.append(i)\n  return positive, negative\n\npositive, negative = score_words(words)\nprint(negative)\nprint(positive)\n\n['bad', 'broken', 'dirty', 'misery', 'blah', 'blah', 'blah', 'broken', 'bitch', 'hard', 'lost', 'hell', 'trouble', 'fire', 'kill', 'stop', 'stop', 'worry', 'attack', 'die', 'sadness', 'lose', 'bitch', 'lose', 'hard', 'killed', 'heartbreaker', 'fire', 'hunger', 'crazy', 'foolish', 'freak', 'rude', 'shake', 'problem', 'dirty', 'killed', 'forget', 'drunk', 'weapons', 'bad', 'sorry', 'forget', 'blame', 'jealous', 'hurt', 'lose', 'broken', 'hard', 'steal', 'fire', 'dangerous', 'stop', 'lose', 'dangerous', 'starving', 'fire', 'no', 'kill', 'lose', 'fool', 'cruel', 'wtf', 'hurts', 'problems', 'lies', 'crying', 'tired', 'cut', 'bummer', 'low', 'no', 'no', 'tears', 'cry', 'sorry', 'sorry', 'bad', 'sick', 'bad', 'liar', 'nervous', 'miss', 'lose', 'hurts', 'hell', 'sucker', 'no', 'no', 'kills']\n['love', 'romance', 'dynamite', 'like', 'love', 'want', 'like', 'dream', 'kiss', 'ha', 'sexy', 'original', 'original', 'love', 'like', 'like', 'love', 'top', 'best', 'party', 'good', 'yeah', 'sexy', 'glory', 'please', 'love', 'cheers', 'super', 'heaven', 'paradise', 'beautiful', 'love', 'like', 'love', 'stronger', 'good', 'glad', 'beauty', 'love', 'party', 'kiss', 'fame', 'lucky', 'clarity', 'best', 'kiss', 'sweet', 'brave', 'beautiful', 'love', 'love', 'love', 'play', 'love', 'party', 'like', 'love', 'applause', 'beautiful', 'like', 'happy', 'treasure', 'love', 'adore', 'love', 'good', 'perfect', 'love', 'yeah', 'party', 'grey', 'love', 'love', 'love', 'like', 'grey', 'grey', 'grey', 'want', 'want', 'love', 'love', 'worth', 'free', 'dear', 'care', 'love', 'like', 'love', 'want', 'easy', 'love', 'feeling', 'like', 'love', 'like', 'alive', 'heroes', 'perfect', 'love', 'celebrate', 'original', 'lovers', 'spark', 'lover', 'love', 'love', 'feeling', 'original', 'ty', 'beautiful', 'like', 'love', 'confident', 'good', 'like', 'original', 'kindness', 'cool', 'perfect', 'like', 'thrills', 'love', 'lover', 'desire', 'wish', 'peculiar', 'original', 'true', 'like', 'champagne', 'beautiful', 'treat', 'better', 'like', 'love', 'mercy', 'like', 'chance', 'praying', 'greatest', 'love', 'rich', 'love', 'love', 'feeling', 'ok', 'kissing', 'love', 'rich', 'free', 'kissing', 'kiss', 'like', 'love', 'lovers', 'perfect', 'love', 'friends', 'want', 'kissing', 'ready', 'love', 'love', 'loved', 'happier', 'truth', 'good', 'love', 'beautiful', 'care', 'like', 'chance', 'chance', 'like']\n\n\n\nmost_positive = nltk.FreqDist(positive).most_common(15)\nplt.barh([x[0] for x in most_positive],[x[1] for x in most_positive], color = \"lightsteelblue\")\nplt.show()\n\n\n\n\n\nmost_negative = nltk.FreqDist(negative).most_common(15)\nplt.barh([x[0] for x in most_negative],[x[1] for x in most_negative], color = \"maroon\")\nplt.show()\n\n\n\n\nThe above data analysis can determine what kind of titles are frequently used for popular songs. Negative words appear far less often in the “title” column, as demonstrated by the maroon figure. Love appears around 40 times in the titles of the most popular tracks, which indicates that it is a commonly used word in song titles. While I cannot deduce whether love is used in a positive or negative context within the title, the use of the word alone is enough to hint towards either a romantic or breakup type of song.\nHere I will include more in depth analysis about the words in the song titles, and further discuss the data visualizations listed below. I hope to better understand what components go into a popular song, and to determine if there are any correlations between variables.\n\nData Visualizations to Include\n\nMore scatter plots comparing popularity to other variables\n\npop vs. dnce\npop vs. bpm\npop vs. val\n\nKaty Perry’s (or a specific artist) song trends\n\nyear vs. pop\ntrends in valence\n\nTop songs for 2010: trends in valence/dnce\nDance pop songs: dnce vs. bpm\n\npossibly comparing these with another genre, or comparing 2 smaller genres to see if there is a difference in overall trends?"
  },
  {
    "objectID": "posts/Topics.html",
    "href": "posts/Topics.html",
    "title": "First File",
    "section": "",
    "text": "We are going to look at data from the 20 Newsgroups dataset. These are postings to newsgroups in 20 different categories.\nScikit-learn has a function for downloading the data. See: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html\n\n\nLatent Dirichlet Allocation: a topic model that generates topics based on a set of documents’ word frequencies.\n\nGet a “dictionary” that has IDs for all the words along with a record of their word frequencies.\nUse our “bag of words” to generate a list for each document containing its words and their frequencies\nUse gensim to generate an LDA model\n\n\n\n\n\n“Gensim is an open-source library for unsupervised topic modeling and natural language processing, using modern statistical machine learning.”\ngensim website\n\n\nfrom sklearn.datasets import fetch_20newsgroups\n\n\ndata = fetch_20newsgroups(remove=(\"headers\", \"footers\", \"quotes\"))\n\n\nprint(data.DESCR)\n\n\nx = data.data\n\n\nlen(x)\n\n\nx[0]\n\n\ndata.target_names\n\n\ndata.target\n\nWe use NLTK to pre-process the words.\n\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\n\n\nmyStopWords = list(punctuation) + stopwords.words('english')\n\n\nx[0]\n\n\n[w for w in word_tokenize(x[0].lower()) if w not in myStopWords]\n\n\ndocs = []\nfor i in x:\n    docs.append([w for w in word_tokenize(i.lower()) if w not in myStopWords])\n\n\ndocs[0]\n\n\nfrom nltk.stem.porter import PorterStemmer\n#from nltk.stem import LancasterStemmer\n\n\n# Create p_stemmer of class PorterStemmer\np_stemmer = PorterStemmer()\n\n\ndocs_stemmed = []\nfor i in docs:\n    docs_stemmed.append([p_stemmer.stem(w) for w in i])\n\n\ndocs_stemmed[0]\n\nHere we use gensim to make the dictionary and corpus structures, and to employ the LDA model to extract groups (aka topics) and the distribution of words for each topic.\n\nfrom gensim import corpora, models\nimport gensim\n\n\ndictionary = corpora.Dictionary(docs_stemmed)\n\n\nlen(dictionary)\n\n\ndictionary.filter_extremes(no_below=10, no_above=0.5)\n# could also trim with keep_n=1000 or similar to keep only the top words\n\n\nlen(dictionary)\n\n\nprint(dictionary.token2id)\n\n\nprint(dictionary.token2id['patient'])\n\n\ndictionary[1668]\n\n\ncorpus = [dictionary.doc2bow(text) for text in docs_stemmed]\n\n\nprint(corpus[30])\n\n\ndictionary[276]\n\n\ndocs_stemmed[30]\n\n\nwordid = corpus[30][0]\nprint(dictionary[wordid[0]],wordid[1])\n\n\nfor i in corpus[30]:\n    print(dictionary[i[0]], i[1])\n\n\nldamodel = gensim.models.ldamodel.LdaModel(corpus, \n                                           num_topics=20, \n                                           id2word = dictionary, \n                                           passes=5)\n\n\nldamodel.show_topics(num_topics=20)\n\n\nfor i in ldamodel.print_topics(num_topics=20, num_words=20):\n    print(i[0])\n    print(i[1])\n    print('\\n')\n\n\ndata.target_names\n\n\nimport matplotlib.pyplot as plt\nimport re\n\n\nre.split(re.escape(' + ') + '|' + re.escape('*'), 'hi + me*4')\n\n\nfig,ax = plt.subplots(5,4,figsize=(15,20))\nax = ax.flatten()\nfor i in ldamodel.print_topics(num_topics=20, num_words=20):\n    x = []\n    y = []\n    count = 0\n    for j in re.split(re.escape(' + ') + '|' + re.escape('*'), i[1]):\n        if count % 2 == 0:\n            y.insert(0,float(j))\n        else:\n            x.insert(0,j)\n        count += 1\n    ax[i[0]].barh(x,y,height=0.5)\nplt.tight_layout()"
  },
  {
    "objectID": "posts/Topics.html#lda",
    "href": "posts/Topics.html#lda",
    "title": "First File",
    "section": "",
    "text": "Latent Dirichlet Allocation: a topic model that generates topics based on a set of documents’ word frequencies.\n\nGet a “dictionary” that has IDs for all the words along with a record of their word frequencies.\nUse our “bag of words” to generate a list for each document containing its words and their frequencies\nUse gensim to generate an LDA model"
  },
  {
    "objectID": "posts/Topics.html#gensim",
    "href": "posts/Topics.html#gensim",
    "title": "First File",
    "section": "",
    "text": "“Gensim is an open-source library for unsupervised topic modeling and natural language processing, using modern statistical machine learning.”\ngensim website\n\n\nfrom sklearn.datasets import fetch_20newsgroups\n\n\ndata = fetch_20newsgroups(remove=(\"headers\", \"footers\", \"quotes\"))\n\n\nprint(data.DESCR)\n\n\nx = data.data\n\n\nlen(x)\n\n\nx[0]\n\n\ndata.target_names\n\n\ndata.target\n\nWe use NLTK to pre-process the words.\n\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\n\n\nmyStopWords = list(punctuation) + stopwords.words('english')\n\n\nx[0]\n\n\n[w for w in word_tokenize(x[0].lower()) if w not in myStopWords]\n\n\ndocs = []\nfor i in x:\n    docs.append([w for w in word_tokenize(i.lower()) if w not in myStopWords])\n\n\ndocs[0]\n\n\nfrom nltk.stem.porter import PorterStemmer\n#from nltk.stem import LancasterStemmer\n\n\n# Create p_stemmer of class PorterStemmer\np_stemmer = PorterStemmer()\n\n\ndocs_stemmed = []\nfor i in docs:\n    docs_stemmed.append([p_stemmer.stem(w) for w in i])\n\n\ndocs_stemmed[0]\n\nHere we use gensim to make the dictionary and corpus structures, and to employ the LDA model to extract groups (aka topics) and the distribution of words for each topic.\n\nfrom gensim import corpora, models\nimport gensim\n\n\ndictionary = corpora.Dictionary(docs_stemmed)\n\n\nlen(dictionary)\n\n\ndictionary.filter_extremes(no_below=10, no_above=0.5)\n# could also trim with keep_n=1000 or similar to keep only the top words\n\n\nlen(dictionary)\n\n\nprint(dictionary.token2id)\n\n\nprint(dictionary.token2id['patient'])\n\n\ndictionary[1668]\n\n\ncorpus = [dictionary.doc2bow(text) for text in docs_stemmed]\n\n\nprint(corpus[30])\n\n\ndictionary[276]\n\n\ndocs_stemmed[30]\n\n\nwordid = corpus[30][0]\nprint(dictionary[wordid[0]],wordid[1])\n\n\nfor i in corpus[30]:\n    print(dictionary[i[0]], i[1])\n\n\nldamodel = gensim.models.ldamodel.LdaModel(corpus, \n                                           num_topics=20, \n                                           id2word = dictionary, \n                                           passes=5)\n\n\nldamodel.show_topics(num_topics=20)\n\n\nfor i in ldamodel.print_topics(num_topics=20, num_words=20):\n    print(i[0])\n    print(i[1])\n    print('\\n')\n\n\ndata.target_names\n\n\nimport matplotlib.pyplot as plt\nimport re\n\n\nre.split(re.escape(' + ') + '|' + re.escape('*'), 'hi + me*4')\n\n\nfig,ax = plt.subplots(5,4,figsize=(15,20))\nax = ax.flatten()\nfor i in ldamodel.print_topics(num_topics=20, num_words=20):\n    x = []\n    y = []\n    count = 0\n    for j in re.split(re.escape(' + ') + '|' + re.escape('*'), i[1]):\n        if count % 2 == 0:\n            y.insert(0,float(j))\n        else:\n            x.insert(0,j)\n        count += 1\n    ax[i[0]].barh(x,y,height=0.5)\nplt.tight_layout()"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/Final Project Notebook Blog.html",
    "href": "posts/Final Project Notebook Blog.html",
    "title": "Spotify Top Songs Analysis",
    "section": "",
    "text": "Kaelyn Sakai • July 2023"
  },
  {
    "objectID": "posts/Final Project Notebook Blog.html#project-introduction",
    "href": "posts/Final Project Notebook Blog.html#project-introduction",
    "title": "Spotify Top Songs Analysis",
    "section": "Project Introduction",
    "text": "Project Introduction\nThe dataset that I plan on investigating further is the Spotify Top Songs Data from Kaggle. The data contains information about a variety of Spotify top songs. I wanted to analyze this, because I have always been interested in music trends and music in general. Music throughout history is consistently changing, and exploring this dataset can help to further understand the types of songs that have been popular recently. The main research question I will be addressing is, “Are there visible trends and themes in the titles and features of top songs and how do these trends contribute to the past and future popularity of specific types of songs?“. The study will focus on data about the top songs on the Spotify charts, investigating a variety of ratings such as danceability, valence, energy that may influence the popularity of a song. Understanding how the variables relate to each other can lead to further understanding of what contributes towards a popular song. Looking at the data can also determine if there truly are patterns seen in music trends, or if popularity is unrelated to any of the song variables. By exploring these datasets, I hope to investigate questions that relate to the longevity of top Spotify songs. With the emergence of music trends through social media and new popular genres, analyzing recent past trends can help to further understand music popularity.\nI am specifically interested in studying music for this analysis, because I am constantly listening to music and consuming music related media. While I have not completed any research projects about music in the past, I am excited to learn more about the subject."
  },
  {
    "objectID": "posts/Final Project Notebook Blog.html#methods-data-exploration-and-analysis",
    "href": "posts/Final Project Notebook Blog.html#methods-data-exploration-and-analysis",
    "title": "Spotify Top Songs Analysis",
    "section": "Methods: Data Exploration and Analysis",
    "text": "Methods: Data Exploration and Analysis\nThis data contains some of the top songs between the years 2010 through 2019. This is a brief overview of the data and what each variable represents.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntop genre\nGenre of the track\n\n\nyear\nThe year the song appeared on Spotify\n\n\nbpm\nBeats per minute of the song\n\n\nnrgy\nEnergy: The energy rating of the song - the higher the nrgy score, the more energetic the song is\n\n\ndnce\nDance: The danceability rating of the song - the higher the dnce score, the easier it is to dance to\n\n\ndB\nDecibels: The overall loudness - the higher the dB, the louder the song\n\n\nlive\nThe higher the value, the more likely the song is a live recording\n\n\nval\nValence: The mood of the song - the higher the valence, the more cheerful the song is\n\n\ndur\nDuration: Length of the song in seconds\n\n\nacous\nAcoustics: The higher the acoustic value, the more acoustic the song is\n\n\nspch\nSpeechiness: The higher the value, the song contains more spoken words\n\n\npop\nPopularity: Measures how popular the song was\n\n\n\n\nimport matplotlib.pyplot as plt\n\n\nimport pandas as pd\ndf = pd.read_csv('spotify-Copy1.csv',encoding='latin-1')\n\n\nOverall Variable Descriptions for All Data (Table 1 Below)\n\n\ndf.describe()\n\n\n\n\n\n\n\n\nUnnamed: 0\nyear\nbpm\nnrgy\ndnce\ndB\nlive\nval\ndur\nacous\nspch\npop\n\n\n\n\ncount\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n\n\nmean\n302.000000\n2014.592040\n118.545605\n70.504146\n64.379768\n-5.578773\n17.774461\n52.225539\n224.674959\n14.326700\n8.358209\n66.520730\n\n\nstd\n174.215384\n2.607057\n24.795358\n16.310664\n13.378718\n2.798020\n13.102543\n22.513020\n34.130059\n20.766165\n7.483162\n14.517746\n\n\nmin\n1.000000\n2010.000000\n0.000000\n0.000000\n0.000000\n-60.000000\n0.000000\n0.000000\n134.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n151.500000\n2013.000000\n100.000000\n61.000000\n57.000000\n-6.000000\n9.000000\n35.000000\n202.000000\n2.000000\n4.000000\n60.000000\n\n\n50%\n302.000000\n2015.000000\n120.000000\n74.000000\n66.000000\n-5.000000\n12.000000\n52.000000\n221.000000\n6.000000\n5.000000\n69.000000\n\n\n75%\n452.500000\n2017.000000\n129.000000\n82.000000\n73.000000\n-4.000000\n24.000000\n69.000000\n239.500000\n17.000000\n9.000000\n76.000000\n\n\nmax\n603.000000\n2019.000000\n206.000000\n98.000000\n97.000000\n-2.000000\n74.000000\n98.000000\n424.000000\n99.000000\n48.000000\n99.000000\n\n\n\n\n\n\n\n\nYear vs. Valence Score Scatter Plot (Figure 1 Below)\n\n\ndf.plot(kind='scatter',x='year',y='val',color='lightblue')\n\n&lt;Axes: xlabel='year', ylabel='val'&gt;\n\n\n\n\n\nThe figure above represents the range of valence for the songs in each year provided in the dataset. As explained in the chart above, the valence of a song is the metric that measures the happiness or mood score.\n\nAverage and Standard Deviation of Song Variables for Each Year (Table 2 Below)\n\n\nx = df[df['year'] == 2010]\nx.describe().loc[['mean', 'std']]\n\n\n\n\n\n\n\n\nUnnamed: 0\nyear\nbpm\nnrgy\ndnce\ndB\nlive\nval\ndur\nacous\nspch\npop\n\n\n\n\nmean\n26.000000\n2010.0\n122.058824\n77.901961\n64.529412\n-4.901961\n21.176471\n57.000000\n229.803922\n11.627451\n8.882353\n64.254902\n\n\nstd\n14.866069\n0.0\n25.308032\n14.953601\n14.412984\n1.360219\n17.120404\n22.001818\n33.858541\n19.993960\n9.322332\n13.227007\n\n\n\n\n\n\n\n\nxi = df[df['year'] == 2011]\nxi.describe().loc[['mean', 'std']]\n\n\n\n\n\n\n\n\nUnnamed: 0\nyear\nbpm\nnrgy\ndnce\ndB\nlive\nval\ndur\nacous\nspch\npop\n\n\n\n\nmean\n78.000000\n2011.0\n119.075472\n74.886792\n63.641509\n-5.018868\n20.943396\n53.698113\n242.566038\n13.339623\n9.660377\n61.867925\n\n\nstd\n15.443445\n0.0\n20.946681\n15.548510\n11.267882\n1.434339\n15.083632\n20.835053\n36.942528\n21.341494\n9.169228\n16.058831\n\n\n\n\n\n\n\n\nxii = df[df['year'] == 2012]\nxii.describe().loc[['mean', 'std']]\n\n\n\n\n\n\n\n\nUnnamed: 0\nyear\nbpm\nnrgy\ndnce\ndB\nlive\nval\ndur\nacous\nspch\npop\n\n\n\n\nmean\n122.000000\n2012.0\n121.085714\n75.485714\n65.714286\n-4.857143\n15.828571\n64.171429\n224.400000\n4.857143\n5.80000\n67.771429\n\n\nstd\n10.246951\n0.0\n21.066242\n12.134955\n9.838614\n1.458098\n10.427581\n19.008490\n24.236822\n9.953252\n2.65463\n14.528037\n\n\n\n\n\n\n\n\nxiii = df[df['year'] == 2013]\nxiii.describe().loc[['mean', 'std']]\n\n\n\n\n\n\n\n\nUnnamed: 0\nyear\nbpm\nnrgy\ndnce\ndB\nlive\nval\ndur\nacous\nspch\npop\n\n\n\n\nmean\n175.000000\n2013.0\n121.676056\n73.873239\n62.042254\n-5.140845\n19.718310\n53.183099\n234.492958\n10.323944\n8.309859\n63.985915\n\n\nstd\n20.639767\n0.0\n26.517258\n15.396595\n11.580077\n1.658707\n14.007328\n21.234951\n42.506427\n15.660482\n7.652435\n12.864673\n\n\n\n\n\n\n\n\nxiv = df[df['year'] == 2014]\nxiii.describe().loc[['mean', 'std']]\n\n\n\n\n\n\n\n\nUnnamed: 0\nyear\nbpm\nnrgy\ndnce\ndB\nlive\nval\ndur\nacous\nspch\npop\n\n\n\n\nmean\n175.000000\n2013.0\n121.676056\n73.873239\n62.042254\n-5.140845\n19.718310\n53.183099\n234.492958\n10.323944\n8.309859\n63.985915\n\n\nstd\n20.639767\n0.0\n26.517258\n15.396595\n11.580077\n1.658707\n14.007328\n21.234951\n42.506427\n15.660482\n7.652435\n12.864673\n\n\n\n\n\n\n\n\nxv = df[df['year'] == 2015]\nxv.describe().loc[['mean', 'std']]\n\n\n\n\n\n\n\n\nUnnamed: 0\nyear\nbpm\nnrgy\ndnce\ndB\nlive\nval\ndur\nacous\nspch\npop\n\n\n\n\nmean\n316.000000\n2015.0\n119.768421\n70.336842\n63.663158\n-5.621053\n18.305263\n52.526316\n223.368421\n16.600000\n7.052632\n64.568421\n\n\nstd\n27.568098\n0.0\n26.789746\n15.790255\n15.005397\n1.638493\n13.969628\n24.575910\n31.089457\n23.090663\n5.617920\n14.352443\n\n\n\n\n\n\n\n\nxvi = df[df['year'] == 2016]\nxvi.describe().loc[['mean', 'std']]\n\n\n\n\n\n\n\n\nUnnamed: 0\nyear\nbpm\nnrgy\ndnce\ndB\nlive\nval\ndur\nacous\nspch\npop\n\n\n\n\nmean\n403.5000\n2016.0\n114.325000\n67.237500\n63.325000\n-6.712500\n17.737500\n45.150000\n220.225000\n15.875000\n8.362500\n64.162500\n\n\nstd\n23.2379\n0.0\n24.059933\n18.687465\n14.102496\n6.334942\n13.144517\n21.101383\n32.699234\n23.247363\n6.531799\n16.237512\n\n\n\n\n\n\n\n\nxvii = df[df['year'] == 2017]\nxvii.describe().loc[['mean', 'std']]\n\n\n\n\n\n\n\n\nUnnamed: 0\nyear\nbpm\nnrgy\ndnce\ndB\nlive\nval\ndur\nacous\nspch\npop\n\n\n\n\nmean\n476.00000\n2017.0\n116.800000\n69.169231\n65.369231\n-5.615385\n15.369231\n52.276923\n222.169231\n16.600000\n9.784615\n69.015385\n\n\nstd\n18.90767\n0.0\n27.667784\n15.353714\n13.759734\n1.868257\n10.263055\n21.697140\n28.243677\n20.081708\n9.148928\n10.982219\n\n\n\n\n\n\n\n\nxviii = df[df['year'] == 2018]\nxviii.describe().loc[['mean', 'std']]\n\n\n\n\n\n\n\n\nUnnamed: 0\nyear\nbpm\nnrgy\ndnce\ndB\nlive\nval\ndur\nacous\nspch\npop\n\n\n\n\nmean\n540.500000\n2018.0\n114.593750\n65.468750\n67.203125\n-5.671875\n14.750000\n48.765625\n217.187500\n12.781250\n8.625000\n72.43750\n\n\nstd\n18.618987\n0.0\n22.458935\n12.989579\n13.148939\n1.426002\n10.222912\n21.838325\n33.112063\n17.942119\n6.913295\n9.87039\n\n\n\n\n\n\n\n\nxix = df[df['year'] == 2019]\nxix.describe().loc[['mean', 'std']]\n\n\n\n\n\n\n\n\nUnnamed: 0\nyear\nbpm\nnrgy\ndnce\ndB\nlive\nval\ndur\nacous\nspch\npop\n\n\n\n\nmean\n588.000000\n2019.0\n112.451613\n64.741935\n69.709677\n-5.774194\n15.161290\n50.806452\n200.645161\n21.741935\n8.129032\n84.354839\n\n\nstd\n9.092121\n0.0\n19.438516\n17.395340\n11.498387\n1.802030\n14.154144\n22.660420\n26.700248\n22.492914\n7.017796\n8.292761\n\n\n\n\n\n\n\nThe tables above represent the average and standard deviation scores for all of the songs in the specified years.\n\nTop 15 Artists with Most Top Spotify Songs vs. Number of Top Songs (Figure 2 Below)\n\n\nc = df['artist'].value_counts().nlargest(15)\nc.plot(kind='bar',color='pink')\n\n&lt;Axes: &gt;\n\n\n\n\n\nFor the figure above, a narrowed down selection of the artists were required to create a comprehensive bar graph. Additional code was necessary to filter out the artists to include. To do this, I used a command to filter the column of “artist” in the dataset, and to include only the 15 artists that appeared most frequently in the list. The number of times these artists appeared in the column was recorded and plotted on the graph.\n\nTop 15 Genres vs. Number of Top Songs from the Genre (Figure 3 Below)\n\n\ng = df['top genre'].value_counts().nlargest(15)\ng.plot(kind='bar',color='mediumturquoise')\n\n&lt;Axes: &gt;\n\n\n\n\n\nSimilar to the figure for the most frequently appearing artists, the data in the graph above needed to be filtered in order to maximize the clarity of the results. A similar command was run to distinguish the top 15 most frequently appearing genres, and these were plotted on a bar graph to demonstrate the amount of times a top song from the genre appeared in the dataset.\n\nKaty Perry Songs: Year vs. Popularity (Figure 4 Below)\n\n\ndf2 = df[df['artist'].str.contains(\"Katy Perry\")]\ndf2.plot(x='year',y='val',kind='scatter',color='turquoise')\n\n&lt;Axes: xlabel='year', ylabel='val'&gt;\n\n\n\n\n\nThe scatterplot above depicts the valence scores and the year of the song for Katy Perry’s 17 songs in the dataset.\n\nPrimary Data Analysis\n\n\nimport requests\nimport matplotlib.pyplot as plt\nimport nltk\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.sentiment import vader\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import opinion_lexicon\nfrom nltk.stem.porter import PorterStemmer\n\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('vader_lexicon')\nnltk.download('opinion_lexicon')\n\n[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n[nltk_data] Downloading package opinion_lexicon to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Package opinion_lexicon is already up-to-date!\n\n\nTrue\n\n\n\nsia = vader.SentimentIntensityAnalyzer()\n\n\ncol_list = df[\"title\"].values.tolist()\ntitle = ' '.join(col_list)\ntitle_lower = title.lower()\n\n\nfrom nltk.tokenize import word_tokenize, sent_tokenize\ndef tokenize(string):\n  sent = sent_tokenize(title_lower)\n  words = []\n  for s in sent:\n      for w in word_tokenize(s):\n          words.append(w)\n  return words\n\nwords = tokenize(title_lower)\nprint(words)\n\n['hey', ',', 'soul', 'sister', 'love', 'the', 'way', 'you', 'lie', 'tik', 'tok', 'bad', 'romance', 'just', 'the', 'way', 'you', 'are', 'baby', 'dynamite', 'secrets', 'empire', 'state', 'of', 'mind', '(', 'part', 'ii', ')', 'broken', 'down', 'only', 'girl', '(', 'in', 'the', 'world', ')', 'club', 'ca', \"n't\", 'handle', 'me', '(', 'feat', '.', 'david', 'guetta', ')', 'marry', 'you', 'cooler', 'than', 'me', '-', 'single', 'mix', 'telephone', 'like', 'a', 'g6', 'omg', '(', 'feat', '.', 'will.i.am', ')', 'eenie', 'meenie', 'the', 'time', '(', 'dirty', 'bit', ')', 'alejandro', 'your', 'love', 'is', 'my', 'drug', 'meet', 'me', 'halfway', 'whataya', 'want', 'from', 'me', 'take', 'it', 'off', 'misery', 'all', 'the', 'right', 'moves', 'animal', 'naturally', 'i', 'like', 'it', 'teenage', 'dream', 'california', 'gurls', '3', 'my', 'first', 'kiss', '-', 'feat', '.', 'ke', '$', 'ha', 'blah', 'blah', 'blah', '(', 'feat', '.', '3oh', '!', '3', ')', 'imma', 'be', 'try', 'sleeping', 'with', 'a', 'broken', 'heart', 'sexy', 'bitch', '(', 'feat', '.', 'akon', ')', 'bound', 'to', 'you', '-', 'burlesque', 'original', 'motion', 'picture', 'soundtrack', 'if', 'i', 'had', 'you', 'rock', 'that', 'body', 'dog', 'days', 'are', 'over', 'something', \"'s\", 'got', 'a', 'hold', 'on', 'me', '-', 'burlesque', 'original', 'motion', 'picture', 'soundtrack', 'does', \"n't\", 'mean', 'anything', 'hard', 'loca', 'you', 'lost', 'me', 'not', 'myself', 'tonight', 'written', 'in', 'the', 'stars', '(', 'feat', '.', 'eric', 'turner', ')', 'dj', 'got', 'us', 'fallin', \"'\", 'in', 'love', '(', 'feat', '.', 'pitbull', ')', 'castle', 'walls', '(', 'feat', '.', 'christina', 'aguilera', ')', 'break', 'your', 'heart', 'hello', 'a', 'thousand', 'years', 'someone', 'like', 'you', 'give', 'me', 'everything', 'just', 'the', 'way', 'you', 'are', 'rolling', 'in', 'the', 'deep', 'run', 'the', 'world', '(', 'girls', ')', 'moves', 'like', 'jagger', '-', 'studio', 'recording', 'from', 'the', 'voice', 'performance', 'love', 'on', 'top', 'grenade', 'tonight', 'tonight', 'what', 'the', 'hell', 'born', 'this', 'way', 'monster', 'marry', 'you', 'best', 'thing', 'i', 'never', 'had', 'party', 'rock', 'anthem', 'we', 'r', 'who', 'we', 'r', 'price', 'tag', 'good', 'life', 'just', 'can\\x92t', 'get', 'enough', 'on', 'the', 'floor', 'what', \"'s\", 'my', 'name', '?', 'yeah', '3x', 'without', 'you', '(', 'feat', '.', 'usher', ')', 'sexy', 'and', 'i', 'know', 'it', 'the', 'edge', 'of', 'glory', 'e.t', '.', 'till', 'the', 'world', 'ends', 'i', 'wan', 'na', 'go', 'blow', 'you', 'and', 'i', 'judas', 'tonight', '(', 'i', \"'m\", 'fuckin', \"'\", 'you', ')', 'please', 'do', \"n't\", 'go', 'we', 'found', 'love', 'marry', 'the', 'night', '1+1', 'hold', 'it', 'against', 'me', 'i', \"'m\", 'into', 'you', 'papi', 'cheers', '(', 'drink', 'to', 'that', ')', 's', '&', 'm', 'remix', 'written', 'in', 'the', 'stars', '(', 'feat', '.', 'eric', 'turner', ')', 'jar', 'of', 'hearts', 'castle', 'walls', '(', 'feat', '.', 'christina', 'aguilera', ')', 'turning', 'page', 'super', 'bass', 'raise', 'your', 'glass', 'invading', 'my', 'mind', 'moment', '4', 'life', '-', 'album', 'version', '(', 'edited', ')', 'last', 'friday', 'night', '(', 't.g.i.f', '.', ')', 'firework', 'muny', '-', 'album', 'version', '(', 'edited', ')', 'titanium', '(', 'feat', '.', 'sia', ')', 'locked', 'out', 'of', 'heaven', 'paradise', 'payphone', 'what', 'makes', 'you', 'beautiful', 'i', 'knew', 'you', 'were', 'trouble', '.', 'call', 'me', 'maybe', 'love', 'you', 'like', 'a', 'love', 'song', 'set', 'fire', 'to', 'the', 'rain', 'we', 'are', 'never', 'ever', 'getting', 'back', 'together', 'stronger', '(', 'what', 'does', \"n't\", 'kill', 'you', ')', 'try', 'starships', 'one', 'more', 'night', 'good', 'time', 'glad', 'you', 'came', 'beauty', 'and', 'a', 'beat', 'international', 'love', 'some', 'nights', 'boyfriend', 'part', 'of', 'me', 'domino', 'where', 'have', 'you', 'been', 'wide', 'awake', 'the', 'one', 'that', 'got', 'away', 'dance', 'again', 'turn', 'up', 'the', 'music', 'lights', '-', 'single', 'version', 'we', 'are', 'young', '(', 'feat', '.', 'janelle', 'monáe', ')', 'diamonds', 'do', \"n't\", 'stop', 'the', 'party', '(', 'feat', '.', 'tjr', ')', 'you', 'da', 'one', 'stereo', 'hearts', '(', 'feat', '.', 'adam', 'levine', ')', 'it', 'will', 'rain', 'blow', 'me', '(', 'one', 'last', 'kiss', ')', 'underneath', 'the', 'tree', 'wake', 'me', 'up', 'story', 'of', 'my', 'life', 'just', 'give', 'me', 'a', 'reason', '(', 'feat', '.', 'nate', 'ruess', ')', 'hall', 'of', 'fame', 'roar', 'we', 'ca', \"n't\", 'stop', 'do', \"n't\", 'you', 'worry', 'child', '-', 'radio', 'edit', 'get', 'lucky', '(', 'feat', '.', 'pharrell', 'williams', '&', 'nile', 'rodgers', ')', '-', 'radio', 'edit', 'wrecking', 'ball', 'impossible', 'blurred', 'lines', 'heart', 'attack', 'we', 'are', 'never', 'ever', 'getting', 'back', 'together', 'die', 'young', 'clarity', 'summertime', 'sadness', '(', 'lana', 'del', 'rey', 'vs.', 'cedric', 'gervais', ')', '-', 'cedric', 'gervais', 'remix', 'under', 'control', 'everybody', 'talks', 'hold', 'on', ',', 'we', \"'re\", 'going', 'home', 'best', 'song', 'ever', 'kiss', 'you', 'sweet', 'nothing', '(', 'feat', '.', 'florence', 'welch', ')', 'lose', 'yourself', 'to', 'dance', 'work', 'bitch', 'brave', 'ca', \"n't\", 'hold', 'us', '(', 'feat', '.', 'ray', 'dalton', ')', 'feel', 'this', 'moment', '(', 'feat', '.', 'christina', 'aguilera', ')', 'beneath', 'your', 'beautiful', 'let', 'me', 'love', 'you', '(', 'until', 'you', 'learn', 'to', 'love', 'yourself', ')', 'thrift', 'shop', '(', 'feat', '.', 'wanz', ')', 'if', 'i', 'lose', 'myself', '-', 'alesso', 'vs', 'onerepublic', 'the', 'way', 'suit', '&', 'tie', '#', 'thatpower', 'i', 'love', 'it', '(', 'feat', '.', 'charli', 'xcx', ')', 'play', 'hard', '(', 'feat', '.', 'ne-yo', '&', 'akon', ')', '-', 'new', 'edit', 'daylight', 'love', 'somebody', 'a', 'little', 'party', 'never', 'killed', 'nobody', '(', 'all', 'we', 'got', ')', 'move', 'walks', 'like', 'rihanna', 'rock', 'n', 'roll', 'heartbreaker', 'mirrors', '-', 'radio', 'edit', 'next', 'to', 'me', 'made', 'in', 'the', 'usa', 'clown', 'girl', 'on', 'fire', '(', 'feat', '.', 'nicki', 'minaj', ')', '-', 'inferno', 'version', 'tko', 'come', '&', 'get', 'it', 'live', 'it', 'up', 'we', 'own', 'the', 'night', 'atlas', '-', 'from', '\\x93the', 'hunger', 'games', ':', 'catching', 'fire\\x94', 'soundtrack', 'what', 'about', 'love', 'take', 'back', 'the', 'night', 'applause', 'anything', 'could', 'happen', 'finally', 'found', 'you', 'pom', 'poms', '#', 'beautiful', 'how', 'ya', 'doin', \"'\", '?', '(', 'feat', '.', 'missy', 'elliott', ')', 'crazy', 'kids', '(', 'feat', '.', 'will.i.am', ')', 'ooh', 'la', 'la', '(', 'from', '``', 'the', 'smurfs', '2', \"''\", ')', 'people', 'like', 'us', 'overdose', 'right', 'now', '-', 'dyro', 'radio', 'edit', 'give', 'it', '2', 'u', 'foolish', 'games', 'outta', 'nowhere', '(', 'feat', '.', 'danny', 'mercer', ')', 'freak', 'all', 'of', 'me', 'stay', 'with', 'me', 'summer', 'happy', '-', 'from', '``', 'despicable', 'me', '2', \"''\", 'rude', 'shake', 'it', 'off', 'dark', 'horse', 'hey', 'brother', 'maps', 'treasure', 'let', 'her', 'go', 'problem', 'pompeii', 'team', 'love', 'me', 'again', 'latch', 'adore', 'you', 'love', 'never', 'felt', 'so', 'good', 'burn', 'she', 'looks', 'so', 'perfect', 'fancy', 'talk', 'dirty', '(', 'feat', '.', '2', 'chainz', ')', 'gorilla', 'human', 'young', 'girls', 'wiggle', '(', 'feat', '.', 'snoop', 'dogg', ')', 'love', 'runs', 'out', 'this', 'is', 'how', 'we', 'do', 'mmm', 'yeah', '(', 'feat', '.', 'pitbull', ')', 'a', 'little', 'party', 'never', 'killed', 'nobody', '(', 'all', 'we', 'got', ')', '#', 'selfie', 'partition', 'birthday', 'g.u.y', '.', 'stay', 'the', 'night', '-', 'featuring', 'hayley', 'williams', 'of', 'paramore', 'let', 'it', 'go', '-', 'from', '``', 'frozen', '/', 'single', 'version', 'wings', 'ca', \"n't\", 'remember', 'to', 'forget', 'you', '(', 'feat', '.', 'rihanna', ')', 'shot', 'me', 'down', '(', 'feat', '.', 'skylar', 'grey', ')', '-', 'radio', 'edit', 'say', 'something', 'a', 'sky', 'full', 'of', 'stars', 'come', 'get', 'it', 'bae', 'chandelier', 'xo', 'we', 'are', 'one', '(', 'ole', 'ola', ')', '[', 'the', 'official', '2014', 'fifa', 'world', 'cup', 'song', ']', 'not', 'about', 'angels', 'drunk', 'in', 'love', 'anaconda', 'boom', 'clap', '-', 'from', 'the', 'motion', 'picture', 'das', 'schicksal', 'ist', 'ein', 'mieser', 'verräter', 'la', 'la', 'la', '(', 'brasil', '2014', ')', '(', 'feat', '.', 'carlinhos', 'brown', ')', 'tee', 'shirt', '-', 'soundtrack', 'version', 'words', 'as', 'weapons', 'you', \"'re\", 'mine', '(', 'eternal', ')', 'sheezus', 'cannonball', 'it', \"'s\", 'on', 'again', '-', 'main', 'soundtrack', 'i', 'luh', 'ya', 'papi', 'not', 'a', 'bad', 'thing', 'thinking', 'out', 'loud', 'i', \"'m\", 'not', 'the', 'only', 'one', 'the', 'hills', 'love', 'yourself', 'uptown', 'funk', 'take', 'me', 'to', 'church', 'sugar', 'sorry', 'fourfiveseconds', 'love', 'me', 'like', 'you', 'do', '-', 'from', '``', 'fifty', 'shades', 'of', 'grey', \"''\", 'earned', 'it', '(', 'fifty', 'shades', 'of', 'grey', ')', '-', 'from', 'the', '``', 'fifty', 'shades', 'of', 'grey', \"''\", 'soundtrack', 'what', 'do', 'you', 'mean', '?', 'stitches', 'want', 'to', 'want', 'me', 'my', 'house', 'waves', '-', 'robin', 'schulz', 'radio', 'edit', 'night', 'changes', 'how', 'deep', 'is', 'your', 'love', 'never', 'forget', 'you', 'love', 'me', 'harder', 'animals', 'blame', 'worth', 'it', 'break', 'free', 'do', \"n't\", 'elastic', 'heart', 'rather', 'be', '(', 'feat', '.', 'jess', 'glynne', ')', 'hello', 'dear', 'future', 'husband', '43776', 'the', 'heart', 'wants', 'what', 'it', 'wants', 'hey', 'mama', '(', 'feat', '.', 'nicki', 'minaj', ',', 'bebe', 'rexha', '&', 'afrojack', ')', 'genie', 'in', 'a', 'bottle', 'company', 'sing', 'jealous', '-', 'remix', 'really', 'do', \"n't\", 'care', 'downtown', '(', 'feat', '.', 'melle', 'mel', ',', 'grandmaster', 'caz', ',', 'kool', 'moe', 'dee', '&', 'eric', 'nally', ')', 'only', 'love', 'can', 'hurt', 'like', 'this', 'heartbeat', 'song', 'up', 'trumpets', 'runnin', \"'\", '(', 'lose', 'it', 'all', ')', 'same', 'old', 'love', 'i', 'want', 'you', 'to', 'know', 'lips', 'are', 'movin', 'i', \"'ll\", 'show', 'you', 'here', 'i', 'lived', 'fireball', '(', 'feat', '.', 'john', 'ryan', ')', 'easy', 'love', 'the', 'feeling', 'i', 'really', 'like', 'you', 'bo', '$', '$', 'sugar', 'focus', 'all', 'about', 'that', 'bass', 'on', 'my', 'mind', 'love', 'me', 'like', 'you', 'broken', 'arrows', 'booty', 'what', 'do', 'you', 'mean', '?', '-', 'acoustic', 'mark', 'my', 'words', 'lay', 'it', 'all', 'on', 'me', 'american', 'oxygen', 'bang', 'bang', 'reality', '-', 'radio', 'edit', 'alive', 'sugar', '(', 'feat', '.', 'francesco', 'yates', ')', 'been', 'you', 'prayer', 'in', 'c', '-', 'robin', 'schulz', 'radio', 'edit', 'see', 'you', 'again', '(', 'feat', '.', 'charlie', 'puth', ')', 'heroes', '(', 'we', 'could', 'be', ')', 'feel', 'the', 'light', '-', 'from', 'the', '``', 'home', \"''\", 'soundtrack', 'perfect', 'ghosttown', 'bang', 'my', 'head', '(', 'feat', '.', 'sia', '&', 'fetty', 'wap', ')', 'bloodstream', 'living', 'for', 'love', 'baby', 'do', \"n't\", 'lie', 'do', \"n't\", 'be', 'so', 'hard', 'on', 'yourself', 'steal', 'my', 'girl', 'celebrate', '(', 'from', 'the', 'original', 'motion', 'picture', '``', 'penguins', 'of', 'madagascar', \"''\", ')', 'we', 'are', 'here', 'st', 'jude', 'yesterday', '(', 'feat', '.', 'bebe', 'rexha', ')', 'time', 'of', 'our', 'lives', 'sparks', 'mr.', 'put', 'it', 'down', 'legendary', 'lovers', 'spark', 'the', 'fire', 'run', 'run', 'run', 'let', 'me', 'be', 'your', 'lover', 'dangerous', 'l.a.love', '(', 'la', 'la', ')', 'the', 'hills', 'love', 'yourself', 'cake', 'by', 'the', 'ocean', 'do', \"n't\", 'let', 'me', 'down', 'in', 'the', 'name', 'of', 'love', 'into', 'you', 'this', 'is', 'what', 'you', 'came', 'for', 'million', 'reasons', 'needed', 'me', '7', 'years', 'ca', \"n't\", 'stop', 'the', 'feeling', '!', '(', 'original', 'song', 'from', 'dreamworks', 'animation', \"'s\", '``', 'trolls', \"''\", ')', 'work', 'from', 'home', '(', 'feat', '.', 'ty', 'dolla', '$', 'ign', ')', 'scars', 'to', 'your', 'beautiful', 'like', 'i', \"'m\", 'gon', 'na', 'lose', 'you', '(', 'feat', '.', 'john', 'legend', ')', 'work', 'stitches', 'me', ',', 'myself', '&', 'i', 'i', 'took', 'a', 'pill', 'in', 'ibiza', '-', 'seeb', 'remix', 'dangerous', 'woman', 'starving', 'shout', 'out', 'to', 'my', 'ex', 'electric', 'love', 'confident', 'too', 'good', 'roses', 'cold', 'water', '(', 'feat', '.', 'justin', 'bieber', '&', 'mø', ')', 'me', 'too', 'light', 'it', 'up', '(', 'feat', '.', 'nyla', '&', 'fuse', 'odg', ')', '[', 'remix', ']', 'ai', \"n't\", 'your', 'mama', 'close', 'toothbrush', 'all', 'we', 'know', 'final', 'song', 'company', 'hands', 'to', 'myself', 'all', 'i', 'ask', 'just', 'like', 'fire', '(', 'from', 'the', 'original', 'motion', 'picture', '``', 'alice', 'through', 'the', 'looking', 'glass', \"''\", ')', 'no', 'kill', 'em', 'with', 'kindness', 'cool', 'girl', 'runnin', \"'\", '(', 'lose', 'it', 'all', ')', 'here', 'perfect', 'illusion', 'pillowtalk', 'out', 'of', 'the', 'woods', 'rise', 'wherever', 'i', 'go', 'body', 'say', 'do', \"n't\", 'be', 'a', 'fool', 'like', 'i', 'would', 'cheap', 'thrills', 'i', 'got', 'you', 'run', 'away', 'with', 'me', 'cruel', '(', 'feat', '.', 'zayn', ')', 'send', 'my', 'love', '(', 'to', 'your', 'new', 'lover', ')', 'wtf', '(', 'where', 'they', 'from', ')', 'desire', 'when', 'we', 'were', 'young', 'i', 'know', 'what', 'you', 'did', 'last', 'summer', 'wish', 'that', 'you', 'were', 'here', '-', 'from', '\\x93miss', 'peregrine\\x92s', 'home', 'for', 'peculiar', 'children\\x94', 'original', 'motion', 'picture', 'hurts', 'change', 'make', 'me', '...', '(', 'feat', '.', 'g-eazy', ')', 'keeping', 'your', 'head', 'up', 'true', 'colors', 'make', 'me', 'like', 'you', 'champagne', 'problems', 'blown', 'start', 'pep', 'rally', 'higher', 'invitation', 'one', 'call', 'away', '(', 'feat', '.', 'tyga', ')', '-', 'remix', 'beautiful', 'birds', '(', 'feat', '.', 'birdy', ')', 'little', 'lies', 'do', 'you', 'wan', 'na', 'come', 'over', '?', 'burnitup', '!', 'picky', '-', 'remix', 'behind', 'your', 'back', 'million', 'years', 'ago', 'shape', 'of', 'you', 'closer', 'starboy', 'treat', 'you', 'better', 'that', \"'s\", 'what', 'i', 'like', 'let', 'me', 'love', 'you', 'i', 'feel', 'it', 'coming', 'mercy', 'side', 'to', 'side', 'stay', 'it', 'ai', \"n't\", 'me', '(', 'with', 'selena', 'gomez', ')', 'malibu', 'something', 'just', 'like', 'this', 'rockabye', '(', 'feat', '.', 'sean', 'paul', '&', 'anne-marie', ')', 'i', 'don\\x92t', 'wan', 'na', 'live', 'forever', '(', 'fifty', 'shades', 'darker', ')', 'my', 'way', 'i', \"'m\", 'the', 'one', '(', 'feat', '.', 'justin', 'bieber', ',', 'quavo', ',', 'chance', 'the', 'rapper', '&', 'lil', 'wayne', ')', 'praying', 'despacito', '-', 'remix', 'the', 'greatest', 'there', 'for', 'you', 'paris', 'crying', 'in', 'the', 'club', 'mama', 'slide', '(', 'feat', '.', 'frank', 'ocean', '&', 'migos', ')', 'swish', 'swish', 'chained', 'to', 'the', 'rhythm', 'cold', '(', 'feat', '.', 'future', ')', 'love', 'reggaetón', 'lento', '(', 'remix', ')', 'all', 'i', 'ask', 'first', 'time', 'the', 'cure', 'how', 'far', 'i', \"'ll\", 'go', '-', 'from', '``', 'moana', \"''\", 'bodak', 'yellow', 'rich', 'love', '(', 'with', 'seeb', ')', 'tired', 'came', 'here', 'for', 'love', '24k', 'magic', 'strip', 'that', 'down', '(', 'feat', '.', 'quavo', ')', 'cut', 'to', 'the', 'feeling', 'ok', '-', 'spotify', 'version', 'bon', 'appétit', 'summer', 'bummer', '(', 'feat', '.', 'a', '$', 'ap', 'rocky', '&', 'playboi', 'carti', ')', 'get', 'low', '(', 'with', 'liam', 'payne', ')', 'kissing', 'strangers', 'slow', 'hands', 'younger', 'now', 'body', 'moves', 'reality', '(', 'feat', '.', 'janieck', 'devy', ')', '-', 'radio', 'edit', 'angel', 'touch', '(', 'feat', '.', 'kid', 'ink', ')', 'we', 'do', \"n't\", 'talk', 'anymore', '-', 'droeloe', 'remix', 'love', 'incredible', '(', 'feat', '.', 'camila', 'cabello', ')', 'no', 'vacancy', '(', 'with', 'sebastián', 'yatra', ')', 'rich', 'boy', 'lust', 'for', 'life', '(', 'with', 'the', 'weeknd', ')', 'greenlight', '(', 'feat', '.', 'flo', 'rida', '&', 'lunchmoney', 'lewis', ')', 'influence', 'remember', 'i', 'told', 'you', 'messin', \"'\", 'around', 'water', 'under', 'the', 'bridge', 'free', 'me', 'kissing', 'strangers', '-', 'remix', 'a', 'l', 'i', 'e', 'n', 's', 'one', 'kiss', '(', 'with', 'dua', 'lipa', ')', 'havana', '(', 'feat', '.', 'young', 'thug', ')', 'i', 'like', 'it', 'new', 'rules', 'there', \"'s\", 'nothing', 'holdin', \"'\", 'me', 'back', 'no', 'tears', 'left', 'to', 'cry', 'idgaf', 'in', 'my', 'blood', 'wolves', 'dusk', 'till', 'dawn', '-', 'radio', 'edit', 'attention', 'electricity', '(', 'with', 'dua', 'lipa', ')', 'love', 'on', 'the', 'brain', 'let', 'me', 'go', '(', 'with', 'alesso', ',', 'florida', 'georgia', 'line', '&', 'watt', ')', 'silence', 'sorry', 'not', 'sorry', 'shallow', '-', 'radio', 'edit', 'these', 'days', 'what', 'lovers', 'do', '(', 'feat', '.', 'sza', ')', 'finesse', '-', 'remix', ';', 'feat', '.', 'cardi', 'b', 'perfect', 'duet', '(', 'ed', 'sheeran', '&', 'beyoncé', ')', 'bad', 'at', 'love', 'him', '&', 'i', '(', 'with', 'halsey', ')', 'friends', '(', 'with', 'bloodpop®', ')', 'wild', 'thoughts', '(', 'feat', '.', 'rihanna', '&', 'bryson', 'tiller', ')', 'my', 'my', 'my', '!', 'capital', 'letters', 'sick', 'boy', 'tequila', 'look', 'what', 'you', 'made', 'me', 'do', 'youth', '(', 'feat', '.', 'khalid', ')', 'bad', 'liar', 'anywhere', 'say', 'something', 'chun-li', 'sign', 'of', 'the', 'times', 'familiar', 'let', 'me', 'supernova', 'nervous', 'first', 'time', 'end', 'game', 'mi', 'gente', '(', 'feat', '.', 'beyoncé', ')', 'lemon', 'for', 'you', '(', 'with', 'rita', 'ora', ')', 'want', 'to', 'what', 'i', 'need', '(', 'feat', '.', 'kehlani', ')', 'wait', 'what', 'about', 'us', 'kissing', 'strangers', '2u', '(', 'feat', '.', 'justin', 'bieber', ')', 'walk', 'on', 'water', '(', 'feat', '.', 'beyoncé', ')', 'this', 'town', 'girls', '(', 'feat', '.', 'cardi', 'b', ',', 'bebe', 'rexha', '&', 'charli', 'xcx', ')', 'move', 'to', 'miami', 'miss', 'you', '(', 'with', 'major', 'lazer', '&', 'tory', 'lanez', ')', 'filthy', 'never', 'be', 'the', 'same', '-', 'radio', 'edit', 'ferrari', 'supplies', 'boom', 'boom', '...', 'ready', 'for', 'it', '?', '-', 'bloodpop®', 'remix', 'drip', '(', 'feat', '.', 'migos', ')', 'tell', 'me', 'you', 'love', 'me', '-', 'notd', 'remix', 'memories', 'lose', 'you', 'to', 'love', 'me', 'someone', 'you', 'loved', 'señorita', 'how', 'do', 'you', 'sleep', '?', 'south', 'of', 'the', 'border', '(', 'feat', '.', 'camila', 'cabello', '&', 'cardi', 'b', ')', 'trampoline', '(', 'with', 'zayn', ')', 'happier', 'truth', 'hurts', 'good', 'as', 'hell', '(', 'feat', '.', 'ariana', 'grande', ')', '-', 'remix', 'higher', 'love', 'only', 'human', 'beautiful', 'people', '(', 'feat', '.', 'khalid', ')', 'sucker', 'do', \"n't\", 'call', 'me', 'up', 'i', 'do', \"n't\", 'care', '(', 'with', 'justin', 'bieber', ')', 'talk', '(', 'feat', '.', 'disclosure', ')', 'giant', '(', 'with', \"rag'n'bone\", 'man', ')', 'takeaway', 'all', 'around', 'the', 'world', '(', 'la', 'la', 'la', ')', 'girls', 'like', 'you', '(', 'feat', '.', 'cardi', 'b', ')', 'call', 'you', 'mine', 'no', 'guidance', '(', 'feat', '.', 'drake', ')', 'antisocial', '(', 'with', 'travis', 'scott', ')', 'taki', 'taki', '(', 'feat', '.', 'selena', 'gomez', ',', 'ozuna', '&', 'cardi', 'b', ')', 'con', 'calma', '-', 'remix', 'find', 'u', 'again', '(', 'feat', '.', 'camila', 'cabello', ')', 'cross', 'me', '(', 'feat', '.', 'chance', 'the', 'rapper', '&', 'pnb', 'rock', ')', 'no', 'brainer', '(', 'feat', '.', 'justin', 'bieber', ',', 'chance', 'the', 'rapper', '&', 'quavo', ')', 'nothing', 'breaks', 'like', 'a', 'heart', '(', 'feat', '.', 'miley', 'cyrus', ')', 'kills', 'you', 'slowly']\n\n\n\ndef score_words(words):\n  positive = []\n  negative = []\n  for i in words:\n    scores = sia.polarity_scores(i)\n    if scores[\"compound\"] &gt; 0:\n      positive.append(i)\n    elif scores[\"compound\"] &lt; 0:\n      negative.append(i)\n  return positive, negative\n\npositive, negative = score_words(words)\nprint(negative)\nprint(positive)\n\n['bad', 'broken', 'dirty', 'misery', 'blah', 'blah', 'blah', 'broken', 'bitch', 'hard', 'lost', 'hell', 'trouble', 'fire', 'kill', 'stop', 'stop', 'worry', 'attack', 'die', 'sadness', 'lose', 'bitch', 'lose', 'hard', 'killed', 'heartbreaker', 'fire', 'hunger', 'crazy', 'foolish', 'freak', 'rude', 'shake', 'problem', 'dirty', 'killed', 'forget', 'drunk', 'weapons', 'bad', 'sorry', 'forget', 'blame', 'jealous', 'hurt', 'lose', 'broken', 'hard', 'steal', 'fire', 'dangerous', 'stop', 'lose', 'dangerous', 'starving', 'fire', 'no', 'kill', 'lose', 'fool', 'cruel', 'wtf', 'hurts', 'problems', 'lies', 'crying', 'tired', 'cut', 'bummer', 'low', 'no', 'no', 'tears', 'cry', 'sorry', 'sorry', 'bad', 'sick', 'bad', 'liar', 'nervous', 'miss', 'lose', 'hurts', 'hell', 'sucker', 'no', 'no', 'kills']\n['love', 'romance', 'dynamite', 'like', 'love', 'want', 'like', 'dream', 'kiss', 'ha', 'sexy', 'original', 'original', 'love', 'like', 'like', 'love', 'top', 'best', 'party', 'good', 'yeah', 'sexy', 'glory', 'please', 'love', 'cheers', 'super', 'heaven', 'paradise', 'beautiful', 'love', 'like', 'love', 'stronger', 'good', 'glad', 'beauty', 'love', 'party', 'kiss', 'fame', 'lucky', 'clarity', 'best', 'kiss', 'sweet', 'brave', 'beautiful', 'love', 'love', 'love', 'play', 'love', 'party', 'like', 'love', 'applause', 'beautiful', 'like', 'happy', 'treasure', 'love', 'adore', 'love', 'good', 'perfect', 'love', 'yeah', 'party', 'grey', 'love', 'love', 'love', 'like', 'grey', 'grey', 'grey', 'want', 'want', 'love', 'love', 'worth', 'free', 'dear', 'care', 'love', 'like', 'love', 'want', 'easy', 'love', 'feeling', 'like', 'love', 'like', 'alive', 'heroes', 'perfect', 'love', 'celebrate', 'original', 'lovers', 'spark', 'lover', 'love', 'love', 'feeling', 'original', 'ty', 'beautiful', 'like', 'love', 'confident', 'good', 'like', 'original', 'kindness', 'cool', 'perfect', 'like', 'thrills', 'love', 'lover', 'desire', 'wish', 'peculiar', 'original', 'true', 'like', 'champagne', 'beautiful', 'treat', 'better', 'like', 'love', 'mercy', 'like', 'chance', 'praying', 'greatest', 'love', 'rich', 'love', 'love', 'feeling', 'ok', 'kissing', 'love', 'rich', 'free', 'kissing', 'kiss', 'like', 'love', 'lovers', 'perfect', 'love', 'friends', 'want', 'kissing', 'ready', 'love', 'love', 'loved', 'happier', 'truth', 'good', 'love', 'beautiful', 'care', 'like', 'chance', 'chance', 'like']\n\n\n\nFrequency of Positive Words in Top Song Titles (Figure 5 Below)\n\n\nmost_positive = nltk.FreqDist(positive).most_common(15)\nplt.barh([x[0] for x in most_positive],[x[1] for x in most_positive], color = \"lightsteelblue\")\nplt.show()\n\n\n\n\n\nFrequency of Negative Words in Top Song Titles (Figure 6 Below)\n\n\nmost_negative = nltk.FreqDist(negative).most_common(15)\nplt.barh([x[0] for x in most_negative],[x[1] for x in most_negative], color = \"maroon\")\nplt.show()\n\n\n\n\nThe above data analysis and visualizations can determine what variety of words are frequently used for the titles of popular songs. First, I turned all of the song titles in the “title” column into a list, then into a string. The string of titles was then tokenized into a list of words that could be analyzed using vader. The positive and negative words were sorted into their own lists that were then used to create plots of the frequency of the words in song titles."
  },
  {
    "objectID": "posts/Final Project Notebook Blog.html#data-results",
    "href": "posts/Final Project Notebook Blog.html#data-results",
    "title": "Spotify Top Songs Analysis",
    "section": "Data Results",
    "text": "Data Results\nThe overall result of the data analysis is that there are a few patterns that comprise the top songs between 2010 to 2019. As seen in Table 1, both energy and dance scores were high on average. Each year featured a wide variety of valence scores for all of the top songs. As seen from Figure 1, the range of valence scores fluctuated throughout the years, with 2012 having the highest overall valence scores. Table 2 shows an overview of the averages for all of the numerical variables for each year in the dataset. One of the obvious outliers in this data is the fact that 2019 has the highest average popularity score compared to the other years. All of the other values maintained fairly consistent throughout the years. The most popular artists were Katy Perry, with 17 songs on Spotify’s top songs list, and Justin Bieber, with 16 top tracks (Figure 2). Additionally, the most popular genre for all of the songs was dance pop (Figure 3). Almost half, specifically 300 out of 603, of the top tracks were labeled as dance pop. Generally, the songs in the dataset had high energy scores that corresponded with relatively high popularity scores. Figure 4 depicts the distribution of valence scores for each year for Katy Perry’s top 17 songs. There are no clear outliers or trends, which indicates that songs with positive and negative valence can become popular, and that artists make a variety of types of songs.\nWith respect to the primary analysis about song titles for the top Spotify songs, positive words generally appear more frequently than negative words. Negative words appear far less often in the “title” column, as demonstrated by Figure 6. Love appears around 40 times in the titles of the most popular tracks, which indicates that it is a commonly used word in song titles (Figure 5)."
  },
  {
    "objectID": "posts/Final Project Notebook Blog.html#discussion",
    "href": "posts/Final Project Notebook Blog.html#discussion",
    "title": "Spotify Top Songs Analysis",
    "section": "Discussion",
    "text": "Discussion\nThe findings from the song title analysis can be significant in addressing the research question of which types songs were popular in the 2010’s. While the connotation of love within the context of the title cannot be determined solely from this graph, the use of the word alone is enough to hint towards either a romantic or breakup type of song. Regardless of the other variables involved in the song, the appeal of love related songs has proved to be a consistent factor for the top tracks. The discovery that love is the most frequently appearing word in the list of top songs can be explained by the fact that love songs in general are known to be popular (Betkowski, 2016). Because love is such a strong and common emotion, conveying it through songs can relate to a wide population of people. Music has been discovered to be able to reach the brain, which may explain why people feel strongly about love songs and why these songs continue to top charts. Understanding these statistics about love-related songs can help to predict future trends in songs, which can be helpful to artists and record labels that are trying to release popular music.\nAdditionally, the majority of the top Spotify songs were categorized into the dance pop genre. This result also contributes to understanding the research question, because it shows that generally there is a trend in genres that comprise the popular songs list. While there is no clear correlation between song popularity and energy score or dance score, the majority of the songs have relatively high scores for both categories. These high scores indicate that dance and energy scores are relevant for the top Spotify songs, because the overall averages for both are relatively high. Dance pop songs may not always be relatable and sentimental, like the love songs mentioned above, but they do create fun tracks that are popular on the radio. The familiarity and nostalgia from past music is also what makes this genre so popular, hence the nickname, “pop” music.\nOverall, popular songs generally have high energy and dance scores, as seen through the visualizations and tables from this data analysis project. The most frequently appearing word in popular song titles is “love”, which can be connected to the appeal and relatability of love-related songs. The prominence of the “dance pop” genre in the Spotify top songs list can also be reflective of the societal nature to listen to what is trending. Although there are approximately 218 genres that comprise the top Spotify songs in this dataset, half of the songs fall within the “dance pop” category. The everlasting popularity of pop songs can hint at a societal and cultural bias towards media that is relatable and familiar. The increase in average popularity scores for songs between 2010 and 2019 can also contribute to a larger picture of an overall increase in music streaming and technological advancements in music. Because the score represents the relative popularity of the songs compared to the others, the greater average popularity of 2019 songs may mean that the consumption and streaming of songs has also increased since 2010. While media and music continue to progress, some features of songs have persisted throughout time. The consistency of some music features and scores throughout the ten year span of this analysis can indicate a longevity of music trends, and help musicians to predict combinations for future top hits."
  },
  {
    "objectID": "posts/Final Project Notebook Blog.html#sources",
    "href": "posts/Final Project Notebook Blog.html#sources",
    "title": "Spotify Top Songs Analysis",
    "section": "Sources",
    "text": "Sources\nBetkowski, B. (2016, February 10). Why we love love songs. Folio. https://www.ualberta.ca/folio/2016/02/why-we-love-love-songs.html\nSuttie, J. S. J. (n.d.). Why we love music. Greater Good. https://greatergood.berkeley.edu/article/item/why_we_love_music"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]